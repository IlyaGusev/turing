{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from scipy.stats import spearmanr\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV, KFold\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier, KNeighborsRegressor\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.svm import LinearSVC \n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "import lightgbm as lgbm\n",
    "from lightgbm.sklearn import LGBMRegressor, LGBMClassifier\n",
    "import string\n",
    "\n",
    "import itertools\n",
    "\n",
    "np.random.seed(1337)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(\"/usr/share/dict/words\") as wordfile:\n",
    "    words = set(x.strip().lower() for x in wordfile.readlines())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def spearmancorr(est,X,y):\n",
    "    rho, pval = spearmanr(np.reshape(y, (-1, 1)), np.reshape(est.predict(X), (-1, 1)), axis=0)\n",
    "    return rho"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def process_data(path, exclude=[], train=True, vectorizers=[None]*4):\n",
    "    def process_file(path):\n",
    "        user = {'Alice': \"A\",'Bob': \"B\"}\n",
    "        \n",
    "        df = pd.read_json(path).set_index(\"dialogId\")\n",
    "        df['speaker'] = df[\"thread\"].apply(lambda x: [user[msg['userId']] for msg in x])\n",
    "        df['thread'] = df[\"thread\"].apply(lambda x: [msg['text'] for msg in x], convert_dtype=False)\n",
    "        df['thread_raw'] = df[\"thread\"].apply(lambda x: \" \".join(x))\n",
    "        if train:\n",
    "            df[\"qualA\"] = df[\"evaluation\"].apply(lambda x: sorted(x, key=lambda x: x['userId'])[0]['quality'])\n",
    "            df[\"qualB\"] = df[\"evaluation\"].apply(lambda x: sorted(x, key=lambda x: x['userId'])[1]['quality'])\n",
    "            df[\"botA\"] = df[\"users\"].apply(lambda x: sorted(x, key=lambda x: x['id'])[0]['userType'] == 'Bot')\n",
    "            df[\"botB\"] = df[\"users\"].apply(lambda x: sorted(x, key=lambda x: x['id'])[1]['userType'] == 'Bot')\n",
    "        df.drop(['users'], axis=1, inplace=True)\n",
    "        if train:\n",
    "            df.drop(['evaluation'], axis=1, inplace=True)\n",
    "            \n",
    "        return df\n",
    "    \n",
    "    def add_features(data, tfidf_thread=None, tfidf_context=None, count_thread=None, count_context=None):\n",
    "        def preprocess(text, lower, punctuation):\n",
    "            if lower:\n",
    "                text = text.lower()\n",
    "            if punctuation == \"exclude\":\n",
    "                text = text.translate(str.maketrans({p: None for p in string.punctuation}))\n",
    "            elif punctuation == \"separate\":\n",
    "                text = text.translate(str.maketrans({p: \" {} \".format(p) for p in string.punctuation}))\n",
    "\n",
    "            return text\n",
    "\n",
    "        punct_modes = [\"exclude\", \"separate\", \"leave\"]\n",
    "        lower_modes = [True, False]\n",
    "                \n",
    "        for preproc_mode in itertools.product(lower_modes, punct_modes):            \n",
    "            preproc = lambda text: preprocess(text, *preproc_mode)\n",
    "\n",
    "            def get_speaker(speaker):\n",
    "                return lambda row: [preproc(x) for x in np.array(row['thread'])[np.array(row['speaker']) == speaker]]\n",
    "\n",
    "            data[\"thread_split_A_{}_{}\".format(*preproc_mode)] = data.apply(get_speaker(\"A\"), axis=1)\n",
    "            data['thread_split_B_{}_{}'.format(*preproc_mode)] = data.apply(get_speaker(\"B\"), axis=1)\n",
    "            \n",
    "            def join_speaker(speaker):\n",
    "                return lambda row: \" \".join(row[\"thread_split_{}_{}_{}\".format(speaker, *preproc_mode)])\n",
    "            \n",
    "            data[\"thread_joined_A_{}_{}\".format(*preproc_mode)] = data.apply(join_speaker(\"A\"), axis=1)\n",
    "            data[\"thread_joined_B_{}_{}\".format(*preproc_mode)] = data.apply(join_speaker(\"B\"), axis=1)\n",
    "\n",
    "            def get_first(speaker):\n",
    "                return lambda row: \" \".join(row[\"thread_split_{}_{}_{}\".format(speaker, *preproc_mode)])\n",
    "            \n",
    "            data[\"start_A_{}_{}\".format(*preproc_mode)] = data.apply(get_first(\"A\"), axis=1)\n",
    "            data[\"start_B_{}_{}\".format(*preproc_mode)] = data.apply(get_first(\"B\"), axis=1)\n",
    "\n",
    "            if not tfidf_thread:\n",
    "                tfidf_thread = TfidfVectorizer(analyzer='word', ngram_range=(1, 2), max_features=4000)\n",
    "                tfidf_thread.fit(data[\"thread_raw\"])\n",
    "            \n",
    "            data[\"tfidf_all_{}_{}\".format(*preproc_mode)] = tfidf_thread.transform(data[\"thread_raw\"]).toarray().tolist()\n",
    "            data[\"tfidf_A_{}_{}\".format(*preproc_mode)] = tfidf_thread.transform(data[\"thread_joined_A_{}_{}\".format(*preproc_mode)]).toarray().tolist()\n",
    "            data[\"tfidf_B_{}_{}\".format(*preproc_mode)] = tfidf_thread.transform(data[\"thread_joined_B_{}_{}\".format(*preproc_mode)]).toarray().tolist()\n",
    "            data[\"tfidf_start_A_{}_{}\".format(*preproc_mode)] = tfidf_thread.transform(data[\"start_A_{}_{}\".format(*preproc_mode)]).toarray().tolist()\n",
    "            data[\"tfidf_start_B_{}_{}\".format(*preproc_mode)] = tfidf_thread.transform(data[\"start_B_{}_{}\".format(*preproc_mode)]).toarray().tolist()\n",
    "\n",
    "            if not tfidf_context:\n",
    "                tfidf_context = TfidfVectorizer(analyzer='word', ngram_range=(1, 2), max_features=4000)\n",
    "                tfidf_context.fit(data[\"context\"])\n",
    "\n",
    "            data[\"tfidf_context_{}_{}\".format(*preproc_mode)] = tfidf_context.transform(data[\"context\"]).toarray().tolist()\n",
    "\n",
    "            if not count_thread:\n",
    "                count_thread = CountVectorizer(analyzer='word', ngram_range=(1, 2), max_features=4000)\n",
    "                count_thread.fit(data[\"thread_raw\"])\n",
    "\n",
    "            data[\"counts_all_{}_{}\".format(*preproc_mode)] = count_thread.transform(data[\"thread_raw\"]).toarray().tolist()\n",
    "            data[\"counts_A_{}_{}\".format(*preproc_mode)] = count_thread.transform(data[\"thread_joined_A_{}_{}\".format(*preproc_mode)]).toarray().tolist()\n",
    "            data[\"counts_B_{}_{}\".format(*preproc_mode)] = count_thread.transform(data[\"thread_joined_B_{}_{}\".format(*preproc_mode)]).toarray().tolist()\n",
    "            data[\"counts_start_A_{}_{}\".format(*preproc_mode)] = count_thread.transform(data[\"start_A_{}_{}\".format(*preproc_mode)]).toarray().tolist()\n",
    "            data[\"counts_start_B_{}_{}\".format(*preproc_mode)] = count_thread.transform(data[\"start_B_{}_{}\".format(*preproc_mode)]).toarray().tolist()\n",
    "\n",
    "            if not count_context:\n",
    "                count_context = CountVectorizer(analyzer='word', ngram_range=(1, 2), max_features=4000)\n",
    "                count_context.fit(data[\"context\"])\n",
    "\n",
    "            data[\"counts_context_{}_{}\".format(*preproc_mode)] = count_context.transform(data[\"context\"]).toarray().tolist()\n",
    "            \n",
    "            def run_len(target, func):\n",
    "                return lambda row: [func((len(list(g)) for person, g in itertools.groupby(row[\"speaker\"]) if person == target), default=0)]\n",
    "\n",
    "            data[\"f_max_run_A_{}_{}\".format(*preproc_mode)] = data.apply(run_len(\"A\", max), axis=1)\n",
    "            data[\"f_max_run_B_{}_{}\".format(*preproc_mode)] = data.apply(run_len(\"B\", max), axis=1)\n",
    "            data[\"f_min_run_A_{}_{}\".format(*preproc_mode)] = data.apply(run_len(\"A\", min), axis=1)\n",
    "            data[\"f_min_run_B_{}_{}\".format(*preproc_mode)] = data.apply(run_len(\"B\", min), axis=1)\n",
    "\n",
    "            def typo_count(target):\n",
    "                return lambda row: [sum(1 for word in preproc(row[\"thread_joined_{}_{}_{}\".format(target, *preproc_mode)]) if word not in words)]\n",
    "\n",
    "            data[\"f_typos_A_{}_{}\".format(*preproc_mode)] = data.apply(typo_count(\"A\"), axis=1)\n",
    "            data[\"f_typos_B_{}_{}\".format(*preproc_mode)] = data.apply(typo_count(\"B\"), axis=1)\n",
    "            data[\"f_typos_frac_A_{}_{}\".format(*preproc_mode)] = data.apply(lambda row: [row[\"f_typos_A_{}_{}\".format(*preproc_mode)][0] / (1 + len(preproc(row[\"thread_joined_A_{}_{}\".format(*preproc_mode)]).split()))], axis=1)\n",
    "            data[\"f_typos_frac_B_{}_{}\".format(*preproc_mode)] = data.apply(lambda row: [row[\"f_typos_B_{}_{}\".format(*preproc_mode)][0] / (1 + len(preproc(row[\"thread_joined_B_{}_{}\".format(*preproc_mode)]).split()))], axis=1)\n",
    "\n",
    "            \n",
    "            def relevant_words(target):\n",
    "                return lambda row: [sum(1 for word in preproc(row[\"thread_joined_{}_{}_{}\".format(target, *preproc_mode)]) if word in preproc(row['context']))]\n",
    "        \n",
    "            data[\"f_relevant_A_{}_{}\".format(*preproc_mode)] = data.apply(relevant_words(\"A\"), axis=1)\n",
    "            data[\"f_relevant_B_{}_{}\".format(*preproc_mode)] = data.apply(relevant_words(\"B\"), axis=1)\n",
    "            data[\"f_relevant_frac_A_{}_{}\".format(*preproc_mode)] = data.apply(lambda row: [row[\"f_relevant_A_{}_{}\".format(*preproc_mode)][0] / (1 + len(preproc(row[\"thread_joined_A_{}_{}\".format(*preproc_mode)]).split()))], axis=1)\n",
    "            data[\"f_relevant_frac_B_{}_{}\".format(*preproc_mode)] = data.apply(lambda row: [row[\"f_relevant_B_{}_{}\".format(*preproc_mode)][0] / (1 + len(preproc(row[\"thread_joined_B_{}_{}\".format(*preproc_mode)]).split()))], axis=1)\n",
    "\n",
    "        return data, tfidf_thread, tfidf_context, count_thread, count_context\n",
    "            \n",
    "    if os.path.isdir(path):\n",
    "        data = pd.concat(\n",
    "            [\n",
    "                process_file(os.path.join(path, file))\n",
    "                for file in os.listdir(path)\n",
    "                if (\n",
    "                    file.startswith(\"train\") and train or\n",
    "                    file.startswith(\"test\") and not train\n",
    "                ) and file not in exclude\n",
    "            ]\n",
    "        )\n",
    "    else:            \n",
    "        data = process_file(path)\n",
    "        \n",
    "    data, *vectorizers = add_features(data, *vectorizers)\n",
    "    \n",
    "    return data, vectorizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/ipykernel/__main__.py:38: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n"
     ]
    }
   ],
   "source": [
    "data, vectorizers = process_data(\"../data/\", train=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feat_templates = [\n",
    "    'counts_all_{}_{}',\n",
    "    'counts_A_{}_{}',\n",
    "    'counts_B_{}_{}',\n",
    "    'counts_start_A_{}_{}',\n",
    "    'counts_start_B_{}_{}',\n",
    "    'counts_context_{}_{}',\n",
    "    'f_max_run_A_{}_{}',\n",
    "    'f_max_run_B_{}_{}',\n",
    "    'f_min_run_A_{}_{}',\n",
    "    'f_min_run_B_{}_{}',\n",
    "    'f_typos_A_{}_{}',\n",
    "    'f_typos_B_{}_{}',\n",
    "    'f_typos_frac_A_{}_{}',\n",
    "    'f_typos_frac_B_{}_{}',\n",
    "    'f_relevant_A_{}_{}',\n",
    "    'f_relevant_B_{}_{}',\n",
    "    'f_relevant_frac_A_{}_{}',\n",
    "    'f_relevant_frac_B_{}_{}',\n",
    "]\n",
    "\n",
    "features = []\n",
    "\n",
    "punct_modes = [\"exclude\", \"separate\", \"leave\"]\n",
    "lower_modes = [True, False]\n",
    "\n",
    "for template, *preproc_mode in itertools.product(feat_templates, lower_modes, punct_modes):            \n",
    "    features.append(template.format(*preproc_mode))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X =((data[features]).values)\n",
    "X = np.stack([np.concatenate(X[i]) for i in range(X.shape[0])])\n",
    "\n",
    "y_A = data[\"qualA\"].values\n",
    "y_B = data[\"qualB\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LGBMRegressor(boosting_type='gbdt', colsample_bytree=1, drop_rate=0.1,\n",
       "       fair_c=1.0, gaussian_eta=1.0, huber_delta=1.0, learning_rate=0.1,\n",
       "       max_bin=255, max_depth=-1, max_drop=50, min_child_samples=10,\n",
       "       min_child_weight=5, min_split_gain=0, n_estimators=100, nthread=-1,\n",
       "       num_leaves=1000, objective='regression', poisson_max_delta_step=0.7,\n",
       "       reg_alpha=0, reg_lambda=0, seed=0, silent=True, skip_drop=0.5,\n",
       "       subsample=1, subsample_for_bin=50000, subsample_freq=1,\n",
       "       uniform_drop=False, xgboost_dart_mode=False)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_A = LGBMRegressor(n_estimators=100, num_leaves=1000)\n",
    "clf_A.fit(X, y_A)\n",
    "clf_B = LGBMRegressor(n_estimators=100, num_leaves=1000)\n",
    "clf_B.fit(X, y_B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/ipykernel/__main__.py:38: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n"
     ]
    }
   ],
   "source": [
    "test, *_ = process_data(\"../data/test_20170727.json\", train=False, vectorizers=vectorizers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "T =((test[features]).values)\n",
    "T = np.stack([np.concatenate(T[i]) for i in range(T.shape[0])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred_A = clf_A.predict(T)\n",
    "pred_B = clf_B.predict(T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(np.stack([pred_A, pred_B]).T, index=test.index, columns=[\"Alice\", \"Bob\"]).to_csv(\"pred.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
