{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "import os\n",
    "from scipy.stats import spearmanr\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "import lightgbm as lgbm\n",
    "from lightgbm.sklearn import LGBMRegressor, LGBMClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(1337)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def process_data(path, exclude=[], train=True):\n",
    "    user = {'Alice': 1,'Bob': 2}\n",
    "    if os.path.isdir(path):\n",
    "        data = pd.DataFrame()\n",
    "\n",
    "        for file in os.listdir(path):\n",
    "            if (file.startswith(\"train\") and train or file.startswith(\"test\") and not train) and file not in exclude:\n",
    "                print(\"{} loaded\".format(file))\n",
    "                df = pd.read_json(os.path.join(path, file)).set_index(\"dialogId\")\n",
    "                df['speaker'] = df.thread.apply(lambda x: [user[msg['userId']] for msg in x])\n",
    "                df['thread'] = df.thread.apply(lambda x: [msg['text'] for msg in x], convert_dtype=False)\n",
    "                df['thread_raw'] = df.thread.apply(lambda x: \" \".join(x))\n",
    "                if train:\n",
    "                    df[\"qualA\"] = df.evaluation.apply(lambda x: sorted(x, key=lambda x: x['userId'])[0]['quality'])\n",
    "                    df[\"qualB\"] = df.evaluation.apply(lambda x: sorted(x, key=lambda x: x['userId'])[1]['quality'])\n",
    "                    df[\"botA\"] = df.users.apply(lambda x: sorted(x, key=lambda x: x['id'])[0]['userType'] == 'Bot')\n",
    "                    df[\"botB\"] = df.users.apply(lambda x: sorted(x, key=lambda x: x['id'])[1]['userType'] == 'Bot')\n",
    "                df.drop(['users'], axis=1, inplace=True)\n",
    "                if train:\n",
    "                    df.drop(['evaluation'], axis=1, inplace=True)\n",
    "\n",
    "                data = pd.concat([data, df])\n",
    "    else:\n",
    "        df = pd.read_json(path).set_index(\"dialogId\")\n",
    "        df['speaker'] = df.thread.apply(lambda x: [user[msg['userId']] for msg in x])\n",
    "        df['thread'] = df.thread.apply(lambda x: [msg['text'] for msg in x], convert_dtype=False)\n",
    "        df['thread_raw'] = df.thread.apply(lambda x: \" \".join(x))\n",
    "        if train:\n",
    "            df[\"qualA\"] = df.evaluation.apply(lambda x: sorted(x, key=lambda x: x['userId'])[0]['quality'])\n",
    "            df[\"qualB\"] = df.evaluation.apply(lambda x: sorted(x, key=lambda x: x['userId'])[1]['quality'])\n",
    "            df[\"botA\"] = df.users.apply(lambda x: sorted(x, key=lambda x: x['id'])[0]['userType'] == 'Bot')\n",
    "            df[\"botB\"] = df.users.apply(lambda x: sorted(x, key=lambda x: x['id'])[1]['userType'] == 'Bot')\n",
    "        df.drop(['users'], axis=1, inplace=True)\n",
    "        if train:\n",
    "            df.drop(['evaluation'], axis=1, inplace=True)\n",
    "            \n",
    "        data = df\n",
    "        \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prepare(data):\n",
    "    features = []\n",
    "    answers = []\n",
    "    \n",
    "    for row in data.iterrows():\n",
    "        features.append(np.concatenate([row[1]['counts_A'], row[1]['tfidf_A'], row[1]['counts_B'], row[1]['tfidf_B']]))\n",
    "        \n",
    "        try:\n",
    "            answers.append(row[1][\"qualA\"])\n",
    "            train = True\n",
    "        except:\n",
    "            train = False\n",
    "\n",
    "\n",
    "    features = np.stack(features)\n",
    "    \n",
    "    if train:\n",
    "        answers = np.stack(answers)\n",
    "    \n",
    "    if train:\n",
    "        return (features, answers)\n",
    "    else:\n",
    "        return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def spearmancorr(est,X,y):\n",
    "    rho, pval = spearmanr(np.reshape(y, (-1, 1)), np.reshape(est.predict(X), (-1, 1)), axis=0)\n",
    "    return rho"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def filter_(person):\n",
    "    def f(row, speaker):\n",
    "        return \" \".join((np.array(row['thread'])[np.array(row['speaker']) == speaker]))\n",
    "\n",
    "    return lambda x: f(x, person)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_20170724.json loaded\n",
      "train_20170725.json loaded\n",
      "train_20170726.json loaded\n"
     ]
    }
   ],
   "source": [
    "data = process_data(\"../data/\", train=True).sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "data[\"thread_A\"] = data.apply(filter_(1), axis=1)\n",
    "data['thread_B'] = data.apply(filter_(2), axis=1)\n",
    "\n",
    "tfidf = TfidfVectorizer(strip_accents='unicode')\n",
    "data[\"tfidf_all\"] = tfidf.fit_transform(data[\"thread_raw\"]).toarray().tolist()\n",
    "data[\"tfidf_A\"] = tfidf.transform(data[\"thread_A\"]).toarray().tolist()\n",
    "data[\"tfidf_B\"] = tfidf.transform(data[\"thread_B\"]).toarray().tolist()\n",
    "\n",
    "count = CountVectorizer(strip_accents='unicode')\n",
    "data[\"counts_all\"] = count.fit_transform(data[\"thread_raw\"]).toarray().tolist()\n",
    "data[\"counts_A\"] = count.transform(data[\"thread_A\"]).toarray().tolist()\n",
    "data[\"counts_B\"] = count.transform(data[\"thread_B\"]).toarray().tolist()\n",
    "\n",
    "\n",
    "X, y = prepare(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  ................................................................\n",
      "[CV] ................................. , score=0.482771, total=  26.8s\n",
      "[CV]  ................................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   26.8s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................................. , score=0.497285, total=  26.9s\n",
      "[CV]  ................................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:   53.8s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................................. , score=0.321042, total=  23.4s\n",
      "[CV]  ................................................................\n",
      "[CV] ................................. , score=0.389069, total=  27.7s\n",
      "[CV]  ................................................................\n",
      "[CV] ................................. , score=0.583113, total=  29.8s\n",
      "[CV]  ................................................................\n",
      "[CV] ................................. , score=0.342824, total=  27.3s\n",
      "[CV]  ................................................................\n",
      "[CV] ................................. , score=0.538057, total=  29.4s\n",
      "[CV]  ................................................................\n",
      "[CV] ................................. , score=0.472082, total=  24.8s\n",
      "[CV]  ................................................................\n",
      "[CV] ................................. , score=0.511733, total=  31.0s\n",
      "[CV]  ................................................................\n",
      "[CV] ................................. , score=0.484649, total=  27.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:  4.6min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.46226242658776728, 0.080378973613598484)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = BaggingClassifier(LGBMClassifier(n_estimators=100), max_samples=0.8, n_estimators=10)\n",
    "\n",
    "cv = cross_val_score(clf, X, y, cv=10, verbose=3, scoring=spearmancorr)\n",
    "\n",
    "cv.mean(), cv.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_20170724.json loaded\n",
      "train_20170725.json loaded\n"
     ]
    }
   ],
   "source": [
    "train = process_data(\"../data\", exclude=[\"train_20170726.json\"], train=True)\n",
    "\n",
    "train[\"thread_A\"] = train.apply(filter_(1), axis=1)\n",
    "train['thread_B'] = train.apply(filter_(2), axis=1)\n",
    "\n",
    "tfidf = TfidfVectorizer(strip_accents='unicode')\n",
    "train[\"tfidf_all\"] = tfidf.fit_transform(train[\"thread_raw\"]).toarray().tolist()\n",
    "train[\"tfidf_A\"] = tfidf.transform(train[\"thread_A\"]).toarray().tolist()\n",
    "train[\"tfidf_B\"] = tfidf.transform(train[\"thread_B\"]).toarray().tolist()\n",
    "\n",
    "count = CountVectorizer(strip_accents='unicode')\n",
    "train[\"counts_all\"] = count.fit_transform(train[\"thread_raw\"]).toarray().tolist()\n",
    "train[\"counts_A\"] = count.transform(train[\"thread_A\"]).toarray().tolist()\n",
    "train[\"counts_B\"] = count.transform(train[\"thread_B\"]).toarray().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "test = process_data(\"../data/train_20170726.json\", train=True)\n",
    "\n",
    "test[\"thread_A\"] = test.apply(filter_(1), axis=1)\n",
    "test['thread_B'] = test.apply(filter_(2), axis=1)\n",
    "\n",
    "test[\"tfidf_all\"] = tfidf.transform(test[\"thread_raw\"]).toarray().tolist()\n",
    "test[\"tfidf_A\"] = tfidf.transform(test[\"thread_A\"]).toarray().tolist()\n",
    "test[\"tfidf_B\"] = tfidf.transform(test[\"thread_B\"]).toarray().tolist()\n",
    "\n",
    "test[\"counts_all\"] = count.transform(test[\"thread_raw\"]).toarray().tolist()\n",
    "test[\"counts_A\"] = count.transform(test[\"thread_A\"]).toarray().tolist()\n",
    "test[\"counts_B\"] = count.transform(test[\"thread_B\"]).toarray().tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X, y = prepare(train)\n",
    "t, t_y = prepare(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.47179145078532186"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#clf = BaggingClassifier(LGBMClassifier(n_estimators=100), max_samples=0.8, n_estimators=50)\n",
    "clf.fit(X, y)\n",
    "\n",
    "spearmancorr(clf, t, t_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
